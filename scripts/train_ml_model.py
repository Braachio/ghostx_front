"""
iRacing ìˆœìœ„ ì˜ˆì¸¡ ML ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python scripts/train_ml_model.py

í™˜ê²½ ì„¤ì •:
    pip install pandas scikit-learn numpy matplotlib supabase
"""

import os
import sys
import argparse
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
import warnings
warnings.filterwarnings('ignore')

# ê³ ê¸‰ ëª¨ë¸ ì‹œë„ (ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë©´)
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False
    print("â„¹ï¸  XGBoostê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì¹˜í•˜ë©´ ì„±ëŠ¥ì´ í–¥ìƒë  ìˆ˜ ìˆìŠµë‹ˆë‹¤: pip install xgboost")

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False
    print("â„¹ï¸  LightGBMì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì¹˜í•˜ë©´ ì„±ëŠ¥ì´ í–¥ìƒë  ìˆ˜ ìˆìŠµë‹ˆë‹¤: pip install lightgbm")
import matplotlib.pyplot as plt
import joblib
import json
from datetime import datetime
from pathlib import Path

# .env íŒŒì¼ ì§€ì›
try:
    from dotenv import load_dotenv
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ .env íŒŒì¼ ì°¾ê¸°
    env_path = Path(__file__).parent.parent / '.env'
    if env_path.exists():
        load_dotenv(env_path)
        print(f"âœ… .env íŒŒì¼ ë¡œë“œ: {env_path}")
    else:
        # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œë„ ì‹œë„
        load_dotenv()
except ImportError:
    print("â„¹ï¸  python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ ì‚¬ìš©í•˜ë ¤ë©´: pip install python-dotenv")
    pass

# Supabase ì—°ê²° (í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
try:
    from supabase import create_client
    
    # í™˜ê²½ ë³€ìˆ˜ ì½ê¸° (ì—¬ëŸ¬ ì´ë¦„ ì‹œë„)
    SUPABASE_URL = (
        os.getenv('NEXT_PUBLIC_SUPABASE_URL') or 
        os.getenv('SUPABASE_URL') or
        os.environ.get('NEXT_PUBLIC_SUPABASE_URL')
    )
    SUPABASE_KEY = (
        os.getenv('SUPABASE_SERVICE_ROLE_KEY') or 
        os.getenv('SUPABASE_KEY') or
        os.environ.get('SUPABASE_SERVICE_ROLE_KEY')
    )
    
    # ë””ë²„ê¹…: í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    print("\nğŸ” í™˜ê²½ ë³€ìˆ˜ í™•ì¸:")
    print(f"   NEXT_PUBLIC_SUPABASE_URL: {'ì„¤ì •ë¨' if SUPABASE_URL else 'âŒ ì—†ìŒ'}")
    print(f"   SUPABASE_SERVICE_ROLE_KEY: {'ì„¤ì •ë¨' if SUPABASE_KEY else 'âŒ ì—†ìŒ'}")
    
    if not SUPABASE_URL or not SUPABASE_KEY:
        print("\nâš ï¸  Supabase í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("\ní•´ê²° ë°©ë²•:")
        print("1. PowerShellì—ì„œ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •:")
        print("   $env:NEXT_PUBLIC_SUPABASE_URL='your-url'")
        print("   $env:SUPABASE_SERVICE_ROLE_KEY='your-key'")
        print("\n2. ë˜ëŠ” .env íŒŒì¼ ìƒì„± (í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—):")
        print("   NEXT_PUBLIC_SUPABASE_URL=your-url")
        print("   SUPABASE_SERVICE_ROLE_KEY=your-key")
        print("\n3. ë˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ ë‚´ì—ì„œ ì§ì ‘ ì„¤ì • (ë³´ì•ˆ ì£¼ì˜)")
        sys.exit(1)
    
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
    print("âœ… Supabase ì—°ê²° ì„±ê³µ\n")
except ImportError:
    print("âš ï¸  supabase íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("   pip install supabase ì‹¤í–‰í•˜ì„¸ìš”.")
    sys.exit(1)
except Exception as e:
    print(f"âš ï¸  Supabase ì—°ê²° ì‹¤íŒ¨: {e}")
    sys.exit(1)

# Post-grid ëª¨ë“œì—ì„œë§Œ ì‚¬ìš©ë˜ëŠ” íŠ¹ì„±ë“¤
POST_ONLY_FEATURES = [
    'starting_position',
    'starting_rank_pct',
    'qualifying_position',
    'qualifying_best_lap_time',
    'practice_best_lap_time',
    'fastest_qualifying_lap_time',
    # âš ï¸ fastest_race_lap_time ì œê±°: ë ˆì´ìŠ¤ ì¤‘ì— ë°œìƒí•˜ëŠ” ì •ë³´ì´ë¯€ë¡œ ë°ì´í„° ëˆ„ìˆ˜
    # 'fastest_race_lap_time',  # ë ˆì´ìŠ¤ ì‹œì‘ ì „ì—ëŠ” ì•Œ ìˆ˜ ì—†ìŒ!
]


def load_data():
    """Supabaseì—ì„œ í•™ìŠµ ë°ì´í„° ë¡œë“œ"""
    print("ğŸ“¥ ë°ì´í„° ë¡œë“œ ì¤‘...")
    
    # ì „ì²´ ë°ì´í„° ë¡œë“œ (í˜ì´ì§€ë„¤ì´ì…˜)
    all_data = []
    page_size = 1000
    offset = 0
    
    while True:
        response = supabase.table('iracing_ml_training_data')\
            .select('*')\
            .range(offset, offset + page_size - 1)\
            .execute()
        
        if not response.data or len(response.data) == 0:
            break
        
        all_data.extend(response.data)
        offset += page_size
        
        if len(response.data) < page_size:
            break
        
        print(f"   {len(all_data)}ê°œ ë ˆì½”ë“œ ë¡œë“œë¨...")
    
    df = pd.DataFrame(all_data)
    print(f"âœ… ì´ {len(df)}ê°œ ë ˆì½”ë“œ ë¡œë“œ ì™„ë£Œ")
    return df


def preprocess_data(df):
    """ë°ì´í„° ì „ì²˜ë¦¬"""
    print("\nğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
    
    # í•„ìˆ˜ í•„ë“œ í™•ì¸ (ë ˆì´ìŠ¤ ì‹œì‘ ì „ì— ì•Œ ìˆ˜ ìˆëŠ” í•„ë“œë§Œ)
    required_fields = [
        'i_rating', 'safety_rating',
        'avg_opponent_ir', 'max_opponent_ir', 'min_opponent_ir',
        'ir_diff_from_avg', 'sof', 'total_participants',
        'best_lap_time',
        'actual_finish_position'  # íƒ€ê²Ÿ ë³€ìˆ˜
    ]
    # ì œì™¸: starting_position, laps_complete (ë ˆì´ìŠ¤ ì‹œì‘ ì „ì— ì•Œ ìˆ˜ ì—†ìŒ)
    
    # í•„ìˆ˜ í•„ë“œê°€ ëª¨ë‘ ìˆëŠ” ë ˆì½”ë“œë§Œ ì„ íƒ
    initial_count = len(df)
    df_clean = df.dropna(subset=required_fields)
    print(f"   í•„ìˆ˜ í•„ë“œ í™•ì¸: {initial_count}ê°œ â†’ {len(df_clean)}ê°œ")
    
    # average_lap_time null ì²˜ë¦¬ (best_lap_timeìœ¼ë¡œ ëŒ€ì²´)
    if 'average_lap_time' in df_clean.columns:
        null_count = df_clean['average_lap_time'].isna().sum()
        df_clean['average_lap_time'] = df_clean['average_lap_time'].fillna(df_clean['best_lap_time'])
        print(f"   average_lap_time null ì²˜ë¦¬: {null_count}ê°œ ë ˆì½”ë“œ (best_lap_timeìœ¼ë¡œ ëŒ€ì²´)")
    
    # íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ (ê°œì„ )
    print("   íŒŒìƒ ë³€ìˆ˜ ìƒì„± ì¤‘...")
    
    # ìƒëŒ€ ì „ë ¥ ê´€ë ¨ íŒŒìƒ ë³€ìˆ˜
    df_clean['ir_advantage'] = df_clean['ir_diff_from_avg'] / 100
    df_clean['ir_range'] = df_clean['max_opponent_ir'] - df_clean['min_opponent_ir']
    df_clean['ir_rank_pct'] = (
        (df_clean['i_rating'] - df_clean['min_opponent_ir']) / 
        (df_clean['max_opponent_ir'] - df_clean['min_opponent_ir'] + 1)
    )
    
    # ì¶”ê°€ ìƒëŒ€ ì „ë ¥ íŒŒìƒ ë³€ìˆ˜
    df_clean['ir_vs_max'] = df_clean['i_rating'] - df_clean['max_opponent_ir']  # ìµœê³  ìƒëŒ€ì™€ì˜ ì°¨ì´
    df_clean['ir_vs_min'] = df_clean['i_rating'] - df_clean['min_opponent_ir']  # ìµœì € ìƒëŒ€ì™€ì˜ ì°¨ì´
    df_clean['ir_std_estimate'] = df_clean['ir_range'] / 4  # ëŒ€ëµì ì¸ í‘œì¤€í¸ì°¨ ì¶”ì •
    df_clean['ir_relative_to_sof'] = (df_clean['i_rating'] - df_clean['sof']) / df_clean['sof']  # SOF ëŒ€ë¹„ ìƒëŒ€ì  ìœ„ì¹˜
    
    # ì£¼í–‰ íŠ¹ì„± íŒŒìƒ ë³€ìˆ˜
    df_clean['lap_time_diff'] = df_clean['average_lap_time'] - df_clean['best_lap_time']
    df_clean['lap_time_consistency'] = df_clean['lap_time_diff'] / (df_clean['best_lap_time'] + 1)  # ì¼ê´€ì„± (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
    
    if 'starting_position' in df_clean.columns:
        df_clean['starting_rank_pct'] = df_clean['starting_position'] / df_clean['total_participants']
    
    # ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ íŒŒìƒ ë³€ìˆ˜
    df_clean['participant_density'] = df_clean['total_participants']  # ì°¸ê°€ì ë°€ë„ (ì¶”ê°€ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ê°€ëŠ¥)
    
    # âš ï¸ starting_rank_pctëŠ” ì œì™¸ (ë ˆì´ìŠ¤ ì‹œì‘ ì „ì— ì•Œ ìˆ˜ ì—†ìŒ)
    # df_clean['starting_rank_pct'] = df_clean['starting_position'] / df_clean['total_participants']
    
    # ìœ ì €ë³„ SOF êµ¬ê°„ë³„ ì„±ëŠ¥ íŠ¹ì„± ì¶”ê°€ (í•µì‹¬!)
    print("   ìœ ì €ë³„ ìƒëŒ€ ì „ë ¥ êµ¬ê°„ë³„ ì„±ëŠ¥ íŠ¹ì„± ê³„ì‚° ì¤‘...")
    df_clean = add_user_sof_performance_features(df_clean)
    
    # ì‚¬ê³  ì˜í–¥ë„ íŠ¹ì„± ì¶”ê°€
    print("   ì‚¬ê³  ì˜í–¥ë„ íŠ¹ì„± ê³„ì‚° ì¤‘...")
    df_clean = add_incident_impact_features(df_clean)
    
    # ìœ ì €ë³„ ìƒëŒ€ ì „ë ¥ íŠ¹ì„±ë“¤ì˜ NaN ì²˜ë¦¬
    user_ir_diff_features = [
        'user_avg_finish_pct_much_lower',
        'user_avg_finish_pct_lower',
        'user_avg_finish_pct_similar',
        'user_avg_finish_pct_higher',
        'user_avg_finish_pct_much_higher',
        'user_ir_diff_performance_diff',
        'user_expected_finish_pct_by_ir_diff'
    ]
    
    print("   ìœ ì €ë³„ ìƒëŒ€ ì „ë ¥ íŠ¹ì„± NaN ì²˜ë¦¬ ì¤‘...")
    for feature in user_ir_diff_features:
        if feature in df_clean.columns:
            null_count = df_clean[feature].isna().sum()
            if null_count > 0:
                # NaNì„ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´ (í•´ë‹¹ ìœ ì €ì˜ ì „ì²´ í‰ê·  ì„±ëŠ¥ì´ ì—†ìœ¼ë©´ 0.5 ì‚¬ìš©)
                if feature == 'user_ir_diff_performance_diff':
                    # ì„±ëŠ¥ ì°¨ì´ëŠ” 0ìœ¼ë¡œ ëŒ€ì²´ (ì°¨ì´ê°€ ì—†ë‹¤ëŠ” ì˜ë¯¸)
                    df_clean[feature] = df_clean[feature].fillna(0.0)
                elif feature == 'user_expected_finish_pct_by_ir_diff':
                    # ì˜ˆìƒ ì„±ëŠ¥ì€ ì „ì²´ í‰ê·  ì™„ì£¼ìœ¨ë¡œ ëŒ€ì²´
                    if 'actual_finish_position' in df_clean.columns and 'total_participants' in df_clean.columns:
                        avg_finish_pct = (df_clean['actual_finish_position'] / df_clean['total_participants']).median()
                        df_clean[feature] = df_clean[feature].fillna(avg_finish_pct)
                    else:
                        df_clean[feature] = df_clean[feature].fillna(0.5)
                else:
                    # ê° êµ¬ê°„ë³„ í‰ê·  ì™„ì£¼ìœ¨ì€ ì „ì²´ í‰ê·  ì™„ì£¼ìœ¨ë¡œ ëŒ€ì²´
                    if 'actual_finish_position' in df_clean.columns and 'total_participants' in df_clean.columns:
                        avg_finish_pct = (df_clean['actual_finish_position'] / df_clean['total_participants']).median()
                        df_clean[feature] = df_clean[feature].fillna(avg_finish_pct)
                    else:
                        df_clean[feature] = df_clean[feature].fillna(0.5)
                print(f"      {feature}: {null_count}ê°œ NaN ì²˜ë¦¬ ì™„ë£Œ")
    
    # ìµœì¢… NaN í™•ì¸ ë° ì²˜ë¦¬ (ë‚˜ë¨¸ì§€ íŠ¹ì„±ë“¤)
    print("   ìµœì¢… NaN í™•ì¸ ì¤‘...")
    nan_counts = df_clean.isna().sum()
    features_with_nan = nan_counts[nan_counts > 0]
    if len(features_with_nan) > 0:
        print(f"   âš ï¸  NaNì´ ìˆëŠ” íŠ¹ì„±: {len(features_with_nan)}ê°œ")
        for feature, count in features_with_nan.items():
            if feature not in user_ir_diff_features and feature != 'actual_finish_position':
                # ìˆ«ìí˜• íŠ¹ì„±ì€ ì¤‘ì•™ê°’ìœ¼ë¡œ, ê·¸ ì™¸ëŠ” 0ìœ¼ë¡œ ëŒ€ì²´
                if df_clean[feature].dtype in ['float64', 'int64']:
                    median_val = df_clean[feature].median()
                    if pd.isna(median_val):
                        df_clean[feature] = df_clean[feature].fillna(0)
                    else:
                        df_clean[feature] = df_clean[feature].fillna(median_val)
                else:
                    df_clean[feature] = df_clean[feature].fillna(0)
                print(f"      {feature}: {count}ê°œ NaN ì²˜ë¦¬ ì™„ë£Œ")
    
    # ìµœì¢… í™•ì¸: í•™ìŠµì— ì‚¬ìš©í•  íŠ¹ì„±ë“¤ì— NaNì´ ì—†ëŠ”ì§€ í™•ì¸
    print("   í•™ìŠµ íŠ¹ì„± NaN ìµœì¢… í™•ì¸...")
    final_nan_check = df_clean.isna().sum().sum()
    if final_nan_check > 0:
        print(f"   âš ï¸  ê²½ê³ : ì—¬ì „íˆ {final_nan_check}ê°œ NaNì´ ë‚¨ì•„ìˆìŠµë‹ˆë‹¤.")
        # NaNì´ ìˆëŠ” í–‰ ì œê±° (ìµœí›„ì˜ ìˆ˜ë‹¨)
        initial_len = len(df_clean)
        df_clean = df_clean.dropna()
        removed = initial_len - len(df_clean)
        if removed > 0:
            print(f"   {removed}ê°œ ë ˆì½”ë“œ ì œê±°ë¨ (NaN í¬í•¨)")
    else:
        print("   âœ… ëª¨ë“  íŠ¹ì„±ì— NaN ì—†ìŒ")
    
    print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {len(df_clean)}ê°œ ë ˆì½”ë“œ")
    return df_clean


def add_incident_impact_features(df):
    """ì‚¬ê³  ì˜í–¥ë„ íŠ¹ì„± ì¶”ê°€: ì‚¬ê³  ë°œìƒ ì‹œ í‰ê·  ìˆœìœ„ í•˜ë½ ê³„ì‚°"""
    print("   ì‚¬ê³  ì˜í–¥ë„ íŠ¹ì„± ê³„ì‚° ì¤‘...")
    
    # í•„ìš”í•œ ì»¬ëŸ¼ í™•ì¸
    required_cols = ['cust_id', 'actual_finish_position', 'total_participants']
    if not all(col in df.columns for col in required_cols):
        print("   âš ï¸  ì‚¬ê³  ì˜í–¥ë„ ê³„ì‚°ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
        return df
    
    # incidents ì»¬ëŸ¼ í™•ì¸ (actual_incidentsë„ í™•ì¸)
    if 'incidents' not in df.columns:
        if 'actual_incidents' in df.columns:
            # actual_incidentsë¥¼ incidentsë¡œ ë§¤í•‘
            df['incidents'] = df['actual_incidents'].fillna(0)
            print("   âœ… actual_incidentsë¥¼ incidentsë¡œ ë§¤í•‘í–ˆìŠµë‹ˆë‹¤.")
        else:
            # incidentsê°€ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì„¤ì • (ì‚¬ê³  ë°ì´í„° ì—†ìŒ)
            df['incidents'] = 0
            print("   âš ï¸  incidents ì»¬ëŸ¼ì´ ì—†ì–´ 0ìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.")
    
    # ì‹œê°„ ìˆœì„œëŒ€ë¡œ ì •ë ¬ (ê³¼ê±° ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ê¸° ìœ„í•´)
    if 'session_start_time' in df.columns:
        df = df.sort_values(['cust_id', 'session_start_time']).reset_index(drop=True)
    else:
        df = df.sort_values('cust_id').reset_index(drop=True)
    
    # ê° ìœ ì €ë³„ë¡œ ì‚¬ê³  ì˜í–¥ë„ ê³„ì‚°
    incident_impact_stats = {}
    high_incident_risk_flags = {}
    
    unique_users = df['cust_id'].unique()
    print(f"   {len(unique_users)}ëª…ì˜ ìœ ì €ì— ëŒ€í•´ ì‚¬ê³  ì˜í–¥ë„ ê³„ì‚° ì¤‘...")
    
    # ë””ë²„ê¹…: ë ˆì´ìŠ¤ ìˆ˜ ë¶„í¬ í™•ì¸
    user_race_counts = df.groupby('cust_id').size()
    print(f"   ğŸ“Š ë ˆì´ìŠ¤ ìˆ˜ ë¶„í¬:")
    print(f"      - 0ê°œ: {sum(user_race_counts == 0)}ëª…")
    print(f"      - 1ê°œ: {sum(user_race_counts == 1)}ëª…")
    print(f"      - 2ê°œ: {sum(user_race_counts == 2)}ëª…")
    print(f"      - 3ê°œ ì´ìƒ: {sum(user_race_counts >= 3)}ëª…")
    print(f"      - í‰ê·  ë ˆì´ìŠ¤ ìˆ˜: {user_race_counts.mean():.1f}ê°œ")
    print(f"      - ì¤‘ì•™ê°’ ë ˆì´ìŠ¤ ìˆ˜: {user_race_counts.median():.1f}ê°œ")
    
    for user_id in unique_users:
        user_data = df[df['cust_id'] == user_id].copy()
        
        if len(user_data) < 3:  # ìµœì†Œ 3ê°œ ë ˆì´ìŠ¤ë¡œ ì™„í™” (5 -> 3)
            continue
        
        # ì‚¬ê³  ë°œìƒ ë ˆì´ìŠ¤ì™€ ì‚¬ê³  ì—†ëŠ” ë ˆì´ìŠ¤ ë¶„ë¦¬
        races_with_incidents = user_data[user_data['incidents'] > 0]
        races_without_incidents = user_data[user_data['incidents'] == 0]
        
        # ì‚¬ê³  ë°œìƒ í™•ë¥  ê³„ì‚°
        incident_rate = len(races_with_incidents) / len(user_data) if len(user_data) > 0 else 0.0
        
        # ì‚¬ê³  ì˜í–¥ë„ ê³„ì‚°
        if len(races_with_incidents) > 0 and len(races_without_incidents) > 0:
            # ì–‘ìª½ ë°ì´í„°ê°€ ëª¨ë‘ ìˆìœ¼ë©´ ì§ì ‘ ê³„ì‚°
            avg_finish_pct_with_incidents = (races_with_incidents['actual_finish_position'] / 
                                             races_with_incidents['total_participants']).mean()
            avg_finish_pct_without_incidents = (races_without_incidents['actual_finish_position'] / 
                                                races_without_incidents['total_participants']).mean()
            incident_impact = avg_finish_pct_with_incidents - avg_finish_pct_without_incidents
        elif len(races_with_incidents) > 0:
            # ì‚¬ê³  ë°œìƒ ë ˆì´ìŠ¤ë§Œ ìˆëŠ” ê²½ìš°: ì „ì²´ í‰ê· ê³¼ ë¹„êµ
            avg_finish_pct_with_incidents = (races_with_incidents['actual_finish_position'] / 
                                             races_with_incidents['total_participants']).mean()
            overall_avg = (user_data['actual_finish_position'] / user_data['total_participants']).mean()
            incident_impact = avg_finish_pct_with_incidents - overall_avg
        elif len(races_without_incidents) > 0:
            # ì‚¬ê³  ì—†ëŠ” ë ˆì´ìŠ¤ë§Œ ìˆëŠ” ê²½ìš°: 0ìœ¼ë¡œ ì„¤ì • (ì‚¬ê³  ì˜í–¥ ì—†ìŒ)
            incident_impact = 0.0
        else:
            # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°
            incident_impact = 0.0
        
        incident_impact_stats[user_id] = float(incident_impact)
        
        # ì‚¬ê³  ë°œìƒ í™•ë¥ ì´ 0.5 ì´ìƒì´ë©´ ë†’ì€ ìœ„í—˜ìœ¼ë¡œ ê°„ì£¼
        high_incident_risk_flags[user_id] = 1 if incident_rate >= 0.5 else 0
        
        # í‰ê·  ìˆœìœ„ ê³„ì‚° (ì™„ì£¼ìœ¨ë¡œ ì •ê·œí™”)
        avg_finish_pct_with_incidents = (races_with_incidents['actual_finish_position'] / 
                                         races_with_incidents['total_participants']).mean()
        avg_finish_pct_without_incidents = (races_without_incidents['actual_finish_position'] / 
                                            races_without_incidents['total_participants']).mean()
        
        # ì‚¬ê³  ë°œìƒ ì‹œ í‰ê·  ìˆœìœ„ í•˜ë½ (ì™„ì£¼ìœ¨ ì°¨ì´)
        incident_impact = avg_finish_pct_with_incidents - avg_finish_pct_without_incidents
        incident_impact_stats[user_id] = float(incident_impact)
        
        # ì‚¬ê³  ë°œìƒ í™•ë¥  ê³„ì‚°
        incident_rate = len(races_with_incidents) / len(user_data)
        # ì‚¬ê³  ë°œìƒ í™•ë¥ ì´ 0.5 ì´ìƒì´ë©´ ë†’ì€ ìœ„í—˜ìœ¼ë¡œ ê°„ì£¼
        high_incident_risk_flags[user_id] = 1 if incident_rate >= 0.5 else 0
    
    # í†µê³„ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
    df['incident_impact_on_position'] = df['cust_id'].map(incident_impact_stats).fillna(0.0)
    df['high_incident_risk'] = df['cust_id'].map(high_incident_risk_flags).fillna(0)
    
    # ì‚¬ê³  ë°œìƒ ì‹œ í‰ê·  ìˆœìœ„ í•˜ë½ (ìœ„ì¹˜ ë‹¨ìœ„ë¡œ ë³€í™˜)
    # ì™„ì£¼ìœ¨ ì°¨ì´ë¥¼ í‰ê·  ì°¸ê°€ì ìˆ˜ë¡œ ê³±í•˜ì—¬ ì‹¤ì œ ìˆœìœ„ í•˜ë½ìœ¼ë¡œ ë³€í™˜
    avg_participants = df['total_participants'].mean() if 'total_participants' in df.columns else 20
    df['incident_impact_rank_drop'] = df['incident_impact_on_position'] * avg_participants
    
    # í†µê³„ ì¶œë ¥
    total_users = len(unique_users)
    calculated_users = len(incident_impact_stats)
    users_with_impact = sum(1 for v in incident_impact_stats.values() if abs(v) > 0.01)  # 0.01 ì´ìƒ ì°¨ì´ê°€ ìˆëŠ” ê²½ìš°
    high_risk_users = sum(1 for v in high_incident_risk_flags.values() if v == 1)
    
    print(f"   âœ… {calculated_users}ëª…ì˜ ìœ ì €ì— ëŒ€í•´ ì‚¬ê³  ì˜í–¥ë„ ê³„ì‚° ì™„ë£Œ")
    print(f"      - ì‚¬ê³  ì˜í–¥ë„ê°€ ìˆëŠ” ìœ ì €: {users_with_impact}ëª… ({users_with_impact/calculated_users*100:.1f}%)")
    print(f"      - ë†’ì€ ì‚¬ê³  ìœ„í—˜ ìœ ì €: {high_risk_users}ëª… ({high_risk_users/calculated_users*100:.1f}%)")
    if calculated_users < total_users:
        skipped = total_users - calculated_users
        print(f"      - ê³„ì‚° ìƒëµëœ ìœ ì €: {skipped}ëª… (ìµœì†Œ 3ê°œ ë ˆì´ìŠ¤ í•„ìš”)")
    
    return df


def add_user_sof_performance_features(df):
    """ìœ ì €ë³„ ìƒëŒ€ ì „ë ¥(ir_diff_from_avg) êµ¬ê°„ë³„ ì„±ëŠ¥ íŠ¹ì„± ì¶”ê°€ (í•µì‹¬!)"""
    # ir_diff_from_avg êµ¬ê°„ ì •ì˜ (ìƒëŒ€ ì „ë ¥ ëŒ€ë¹„ ë‚´ ìœ„ì¹˜)
    def get_ir_diff_range(ir_diff):
        if pd.isna(ir_diff):
            return None
        if ir_diff < -200:
            return 'much_lower'  # ë‚´ê°€ ìƒëŒ€ í‰ê· ë³´ë‹¤ 200 ì´ìƒ ë‚®ìŒ â†’ ê°•í•œ ìƒëŒ€
        elif ir_diff < -50:
            return 'lower'  # ë‚´ê°€ ìƒëŒ€ í‰ê· ë³´ë‹¤ 50-200 ë‚®ìŒ â†’ ì•½ê°„ ê°•í•œ ìƒëŒ€
        elif ir_diff < 50:
            return 'similar'  # ë¹„ìŠ·í•¨
        elif ir_diff < 200:
            return 'higher'  # ë‚´ê°€ ìƒëŒ€ í‰ê· ë³´ë‹¤ 50-200 ë†’ìŒ â†’ ì•½ê°„ ì•½í•œ ìƒëŒ€
        else:
            return 'much_higher'  # ë‚´ê°€ ìƒëŒ€ í‰ê· ë³´ë‹¤ 200 ì´ìƒ ë†’ìŒ â†’ ì•½í•œ ìƒëŒ€
    
    # ir_diff_from_avg êµ¬ê°„ ì¶”ê°€
    df['ir_diff_range'] = df['ir_diff_from_avg'].apply(get_ir_diff_range)
    
    # ì‹œê°„ ìˆœì„œëŒ€ë¡œ ì •ë ¬ (ê³¼ê±° ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ê¸° ìœ„í•´)
    if 'session_start_time' in df.columns:
        df = df.sort_values(['cust_id', 'session_start_time']).reset_index(drop=True)
    else:
        df = df.sort_values('cust_id').reset_index(drop=True)
    
    print("   ìœ ì €ë³„ ìƒëŒ€ ì „ë ¥ êµ¬ê°„ë³„ ì„±ëŠ¥ íŠ¹ì„± ê³„ì‚° ì¤‘...")
    print("   (ë‚´ iRating vs ìƒëŒ€ í‰ê·  iRating ì°¨ì´ì— ë”°ë¥¸ ì„±ëŠ¥ íŒ¨í„´)")
    
    # ìœ ì €ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ ê³„ì‚°
    new_features = []
    
    # ê° ìƒëŒ€ ì „ë ¥ êµ¬ê°„ë³„ íŠ¹ì„± ì»¬ëŸ¼ ì´ˆê¸°í™”
    for ir_diff_range in ['much_lower', 'lower', 'similar', 'higher', 'much_higher']:
        col_name = f'user_avg_finish_pct_{ir_diff_range}'
        df[col_name] = None
        new_features.append(col_name)
    
    # ìƒëŒ€ ì „ë ¥ ì„±ëŠ¥ ì°¨ì´ (ì•½í•œ ìƒëŒ€ì—ì„œì˜ ì„±ëŠ¥ - ê°•í•œ ìƒëŒ€ì—ì„œì˜ ì„±ëŠ¥)
    df['user_ir_diff_performance_diff'] = None
    new_features.append('user_ir_diff_performance_diff')
    
    # í˜„ì¬ ìƒëŒ€ ì „ë ¥ êµ¬ê°„ì— ëŒ€í•œ ìœ ì €ì˜ ì˜ˆìƒ ì„±ëŠ¥
    df['user_expected_finish_pct_by_ir_diff'] = None
    new_features.append('user_expected_finish_pct_by_ir_diff')
    
    # ìœ ì €ë³„ë¡œ ì²˜ë¦¬
    user_groups = df.groupby('cust_id')
    total_users = len(user_groups)
    processed = 0
    
    for cust_id, user_data in user_groups:
        processed += 1
        if processed % 100 == 0:
            print(f"   ì§„í–‰: {processed}/{total_users}ëª… ìœ ì € ì²˜ë¦¬ë¨")
        
        # ì‹œê°„ ìˆœì„œëŒ€ë¡œ ì •ë ¬
        if 'session_start_time' in user_data.columns:
            user_data = user_data.sort_values('session_start_time')
        
        user_indices = user_data.index.values
        
        # ê° ë ˆì½”ë“œì— ëŒ€í•´ ê³¼ê±° ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì—¬ í†µê³„ ê³„ì‚°
        for i, idx in enumerate(user_indices):
            # í˜„ì¬ ë ˆì½”ë“œ ì´ì „ì˜ ë°ì´í„°ë§Œ ì„ íƒ
            past_data = user_data.iloc[:i]
            
            # ìœ ì €ì˜ ì „ì²´ í‰ê·  ì™„ì£¼ìœ¨ ê³„ì‚° (ê¸°ì¤€ì )
            if len(past_data) > 0:
                all_finish_pcts = past_data['actual_finish_position'] / past_data['total_participants']
                overall_avg_finish_pct = all_finish_pcts.mean()
            else:
                # ê³¼ê±° ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš© (ë‚˜ì¤‘ì— NaN ì²˜ë¦¬)
                overall_avg_finish_pct = None
            
            # ìƒëŒ€ ì „ë ¥ êµ¬ê°„ë³„ í†µê³„ ê³„ì‚° (ìµœì†Œ ë ˆì½”ë“œ ìˆ˜ë¥¼ 1ê°œë¡œ ë‚®ì¶¤)
            stats = {}
            for ir_diff_range in ['much_lower', 'lower', 'similar', 'higher', 'much_higher']:
                if len(past_data) > 0:
                    range_data = past_data[past_data['ir_diff_range'] == ir_diff_range]
                    if len(range_data) >= 1:  # ìµœì†Œ 1ê°œ ë ˆì´ìŠ¤ë§Œ ìˆì–´ë„ ê³„ì‚°
                        # ì‹¤ì œ ì™„ì£¼ ìˆœìœ„ì˜ ë°±ë¶„ìœ¨ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
                        finish_pcts = range_data['actual_finish_position'] / range_data['total_participants']
                        stats[f'avg_finish_pct_{ir_diff_range}'] = finish_pcts.mean()
                    else:
                        stats[f'avg_finish_pct_{ir_diff_range}'] = None
                else:
                    stats[f'avg_finish_pct_{ir_diff_range}'] = None
            
            # ìƒëŒ€ ì „ë ¥ ì„±ëŠ¥ ì°¨ì´ (ê°•í•œ ìƒëŒ€ì—ì„œì˜ ì„±ëŠ¥ - ì•½í•œ ìƒëŒ€ì—ì„œì˜ ì„±ëŠ¥)
            # ì–‘ìˆ˜ = ê°•í•œ ìƒëŒ€ì—ì„œ ë” ì˜í•¨ (ì§‘ì¤‘ë ¥ ìœ í˜•), ìŒìˆ˜ = ì•½í•œ ìƒëŒ€ì—ì„œ ë” ì˜í•¨ (ì••ë„ì  ì‹¤ë ¥ ìœ í˜•)
            # ë” ìœ ì—°í•œ ê³„ì‚°: ê°•í•œ ìƒëŒ€ ê·¸ë£¹ê³¼ ì•½í•œ ìƒëŒ€ ê·¸ë£¹ì˜ í‰ê· ì„ ë¹„êµ
            
            # ê°•í•œ ìƒëŒ€ ê·¸ë£¹ (much_lower, lower)
            strong_opponent_pcts = []
            if stats.get('avg_finish_pct_much_lower') is not None:
                strong_opponent_pcts.append(stats['avg_finish_pct_much_lower'])
            if stats.get('avg_finish_pct_lower') is not None:
                strong_opponent_pcts.append(stats['avg_finish_pct_lower'])
            strong_avg = np.mean(strong_opponent_pcts) if len(strong_opponent_pcts) > 0 else None
            
            # ì•½í•œ ìƒëŒ€ ê·¸ë£¹ (much_higher, higher)
            weak_opponent_pcts = []
            if stats.get('avg_finish_pct_much_higher') is not None:
                weak_opponent_pcts.append(stats['avg_finish_pct_much_higher'])
            if stats.get('avg_finish_pct_higher') is not None:
                weak_opponent_pcts.append(stats['avg_finish_pct_higher'])
            weak_avg = np.mean(weak_opponent_pcts) if len(weak_opponent_pcts) > 0 else None
            
            # ì„±ëŠ¥ ì°¨ì´ ê³„ì‚° (ë” ìœ ì—°í•˜ê²Œ)
            ir_diff_performance_diff = None
            if strong_avg is not None and weak_avg is not None:
                # ë‘ ê·¸ë£¹ ëª¨ë‘ ìˆìœ¼ë©´ ì§ì ‘ ë¹„êµ
                ir_diff_performance_diff = strong_avg - weak_avg
            elif strong_avg is not None and overall_avg_finish_pct is not None:
                # ê°•í•œ ìƒëŒ€ ê·¸ë£¹ë§Œ ìˆìœ¼ë©´ ì „ì²´ í‰ê· ê³¼ ë¹„êµ
                ir_diff_performance_diff = strong_avg - overall_avg_finish_pct
            elif weak_avg is not None and overall_avg_finish_pct is not None:
                # ì•½í•œ ìƒëŒ€ ê·¸ë£¹ë§Œ ìˆìœ¼ë©´ ì „ì²´ í‰ê· ê³¼ ë¹„êµ (ë¶€í˜¸ ë°˜ì „)
                ir_diff_performance_diff = overall_avg_finish_pct - weak_avg
            elif stats.get('avg_finish_pct_similar') is not None and overall_avg_finish_pct is not None:
                # similar êµ¬ê°„ê³¼ ì „ì²´ í‰ê·  ë¹„êµ (ìµœì†Œí•œì˜ ì •ë³´ë¼ë„ í™œìš©)
                ir_diff_performance_diff = stats['avg_finish_pct_similar'] - overall_avg_finish_pct
            elif overall_avg_finish_pct is not None:
                # ê³¼ê±° ë°ì´í„°ëŠ” ìˆì§€ë§Œ íŠ¹ì • êµ¬ê°„ ë°ì´í„°ê°€ ì—†ìœ¼ë©´, ì „ì²´ í‰ê· ì„ ê¸°ì¤€ìœ¼ë¡œ ì¶”ì •
                # í˜„ì¬ ë ˆì´ìŠ¤ì˜ ir_diff_from_avgë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì •
                current_ir_diff = user_data.loc[idx, 'ir_diff_from_avg']
                if pd.notna(current_ir_diff):
                    # ir_diffê°€ ìŒìˆ˜ë©´ (ë‚´ê°€ ì•½í•¨) ê°•í•œ ìƒëŒ€ì—ì„œ ë” ì˜í•  ê°€ëŠ¥ì„±, ì–‘ìˆ˜ë©´ (ë‚´ê°€ ê°•í•¨) ì•½í•œ ìƒëŒ€ì—ì„œ ë” ì˜í•  ê°€ëŠ¥ì„±
                    # í•˜ì§€ë§Œ ì´ê±´ ì¶”ì¸¡ì´ë¯€ë¡œ ë³´ìˆ˜ì ìœ¼ë¡œ 0ì— ê°€ê¹Œìš´ ê°’ ì‚¬ìš©
                    ir_diff_performance_diff = 0.0  # ì„±ëŠ¥ ì°¨ì´ ì—†ìŒìœ¼ë¡œ ê°€ì •
                else:
                    ir_diff_performance_diff = 0.0
            else:
                # ê³¼ê±° ë°ì´í„°ê°€ ì „í˜€ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì„¤ì • (ì„±ëŠ¥ ì°¨ì´ ì—†ìŒ)
                ir_diff_performance_diff = 0.0
            
            stats['ir_diff_performance_diff'] = ir_diff_performance_diff
            
            # ê° ìƒëŒ€ ì „ë ¥ êµ¬ê°„ë³„ íŠ¹ì„± ì¶”ê°€
            for ir_diff_range in ['much_lower', 'lower', 'similar', 'higher', 'much_higher']:
                col_name = f'user_avg_finish_pct_{ir_diff_range}'
                df.at[idx, col_name] = stats.get(f'avg_finish_pct_{ir_diff_range}', None)
            
            # ìƒëŒ€ ì „ë ¥ ì„±ëŠ¥ ì°¨ì´ íŠ¹ì„±
            df.at[idx, 'user_ir_diff_performance_diff'] = stats.get('ir_diff_performance_diff', None)
            
            # í˜„ì¬ ìƒëŒ€ ì „ë ¥ êµ¬ê°„ì— ëŒ€í•œ ìœ ì €ì˜ ì˜ˆìƒ ì„±ëŠ¥
            current_ir_diff_range = user_data.loc[idx, 'ir_diff_range']
            if current_ir_diff_range:
                df.at[idx, 'user_expected_finish_pct_by_ir_diff'] = stats.get(
                    f'avg_finish_pct_{current_ir_diff_range}', None
                )
    
    print(f"   âœ… {len(new_features)}ê°œ ìœ ì € ìƒëŒ€ ì „ë ¥ íŠ¹ì„± ì¶”ê°€")
    
    return df


def encode_categorical_features(df, categorical_cols=['series_id', 'track_id', 'car_id'], use_onehot=True):
    """ì¹´í…Œê³ ë¦¬ ë³€ìˆ˜ ì¸ì½”ë”©"""
    if not use_onehot or not categorical_cols:
        return df, None, []
    
    print(f"\nğŸ”¤ ì¹´í…Œê³ ë¦¬ ë³€ìˆ˜ ì¸ì½”ë”© ì¤‘: {categorical_cols}")
    
    # ì¡´ì¬í•˜ëŠ” ì¹´í…Œê³ ë¦¬ ì»¬ëŸ¼ë§Œ ì„ íƒ
    available_cols = [col for col in categorical_cols if col in df.columns]
    if not available_cols:
        print("   âš ï¸  ì¸ì½”ë”©í•  ì¹´í…Œê³ ë¦¬ ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return df, None, []
    
    # ì›-í•« ì¸ì½”ë”©
    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore', drop='first')
    encoded_features = encoder.fit_transform(df[available_cols])
    
    # ì¸ì½”ë”©ëœ ì»¬ëŸ¼ ì´ë¦„ ìƒì„±
    feature_names = []
    for i, col in enumerate(available_cols):
        categories = encoder.categories_[i]
        for cat in categories[1:]:  # drop='first'ì´ë¯€ë¡œ ì²« ë²ˆì§¸ ì¹´í…Œê³ ë¦¬ ì œì™¸
            feature_names.append(f"{col}_{int(cat)}")
    
    # ì¸ì½”ë”©ëœ ë°ì´í„°í”„ë ˆì„ ìƒì„±
    encoded_df = pd.DataFrame(encoded_features, columns=feature_names, index=df.index)
    
    # ì›ë³¸ ë°ì´í„°í”„ë ˆì„ê³¼ ê²°í•©
    df_encoded = pd.concat([df.drop(columns=available_cols), encoded_df], axis=1)
    
    print(f"   âœ… {len(available_cols)}ê°œ ë³€ìˆ˜ â†’ {len(feature_names)}ê°œ íŠ¹ì„±ìœ¼ë¡œ ì¸ì½”ë”©")
    
    return df_encoded, encoder, feature_names


def train_model(X_train, y_train, X_test, y_test, model_type='random_forest', tune_hyperparams=False):
    """ML ëª¨ë¸ í•™ìŠµ (í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì˜µì…˜ í¬í•¨)"""
    print(f"\nğŸ¤– {model_type} ëª¨ë¸ í•™ìŠµ ì¤‘...")
    
    if model_type == 'random_forest':
        if tune_hyperparams:
            print("   í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì¤‘...")
            param_grid = {
                'n_estimators': [100, 200, 300],
                'max_depth': [15, 20, 25, None],
                'min_samples_split': [5, 10, 15],
                'min_samples_leaf': [2, 5, 10]
            }
            base_model = RandomForestRegressor(random_state=42, n_jobs=-1)
            search = RandomizedSearchCV(
                base_model, param_grid, n_iter=20, cv=3, 
                scoring='r2', n_jobs=-1, random_state=42, verbose=1
            )
            search.fit(X_train, y_train)
            model = search.best_estimator_
            print(f"   ìµœì  íŒŒë¼ë¯¸í„°: {search.best_params_}")
        else:
            model = RandomForestRegressor(
                n_estimators=200,
                max_depth=25,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42,
                n_jobs=-1
            )
    elif model_type == 'gradient_boosting':
        if tune_hyperparams:
            print("   í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì¤‘...")
            param_grid = {
                'n_estimators': [200, 300, 400],
                'learning_rate': [0.05, 0.1, 0.15],
                'max_depth': [8, 10, 12],
                'min_samples_split': [5, 10, 15],
                'min_samples_leaf': [2, 5]
            }
            base_model = GradientBoostingRegressor(random_state=42)
            search = RandomizedSearchCV(
                base_model, param_grid, n_iter=20, cv=3,
                scoring='r2', n_jobs=-1, random_state=42, verbose=1
            )
            search.fit(X_train, y_train)
            model = search.best_estimator_
            print(f"   ìµœì  íŒŒë¼ë¯¸í„°: {search.best_params_}")
        else:
            model = GradientBoostingRegressor(
                n_estimators=300,
                learning_rate=0.1,
                max_depth=12,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42
            )
    elif model_type == 'xgboost' and XGBOOST_AVAILABLE:
        if tune_hyperparams:
            print("   í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì¤‘...")
            param_grid = {
                'n_estimators': [200, 300, 400],
                'learning_rate': [0.05, 0.1, 0.15],
                'max_depth': [6, 8, 10],
                'min_child_weight': [1, 3, 5],
                'subsample': [0.8, 0.9, 1.0]
            }
            base_model = xgb.XGBRegressor(random_state=42, n_jobs=-1)
            search = RandomizedSearchCV(
                base_model, param_grid, n_iter=20, cv=3,
                scoring='r2', n_jobs=-1, random_state=42, verbose=1
            )
            search.fit(X_train, y_train)
            model = search.best_estimator_
            print(f"   ìµœì  íŒŒë¼ë¯¸í„°: {search.best_params_}")
        else:
            model = xgb.XGBRegressor(
                n_estimators=300,
                learning_rate=0.1,
                max_depth=8,
                min_child_weight=3,
                subsample=0.9,
                random_state=42,
                n_jobs=-1
            )
    elif model_type == 'lightgbm' and LIGHTGBM_AVAILABLE:
        if tune_hyperparams:
            print("   í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì¤‘...")
            param_grid = {
                'n_estimators': [200, 300, 400],
                'learning_rate': [0.05, 0.1, 0.15],
                'max_depth': [6, 8, 10],
                'num_leaves': [31, 50, 70],
                'min_child_samples': [10, 20, 30]
            }
            base_model = lgb.LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1)
            search = RandomizedSearchCV(
                base_model, param_grid, n_iter=20, cv=3,
                scoring='r2', n_jobs=-1, random_state=42, verbose=1
            )
            search.fit(X_train, y_train)
            model = search.best_estimator_
            print(f"   ìµœì  íŒŒë¼ë¯¸í„°: {search.best_params_}")
        else:
            model = lgb.LGBMRegressor(
                n_estimators=300,
                learning_rate=0.1,
                max_depth=8,
                num_leaves=50,
                min_child_samples=20,
                random_state=42,
                n_jobs=-1,
                verbose=-1
            )
    else:
        raise ValueError(f"Unknown model type: {model_type} or not available")
    
    # í•™ìŠµ
    model.fit(X_train, y_train)
    
    # ì˜ˆì¸¡
    y_pred = model.predict(X_test)
    
    # í‰ê°€
    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)
    
    print(f"âœ… í•™ìŠµ ì™„ë£Œ")
    print(f"   MAE: {mae:.2f}")
    print(f"   RMSE: {rmse:.2f}")
    print(f"   RÂ²: {r2:.4f}")
    
    return model, {
        'mae': mae,
        'rmse': rmse,
        'r2': r2,
        'y_pred': y_pred,
        'y_test': y_test
    }


def plot_feature_importance(model, features, model_type):
    """íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”"""
    print(f"\nğŸ“Š íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ ì¤‘...")
    
    feature_importance = pd.DataFrame({
        'feature': features,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print("\nìƒìœ„ 10ê°œ íŠ¹ì„±:")
    print(feature_importance.head(10).to_string(index=False))
    
    # ì‹œê°í™”
    plt.figure(figsize=(10, 8))
    plt.barh(feature_importance['feature'], feature_importance['importance'])
    plt.xlabel('Importance')
    plt.title(f'{model_type} - Feature Importance')
    plt.gca().invert_yaxis()
    plt.tight_layout()
    
    # ì €ì¥
    output_dir = 'ml_models'
    os.makedirs(output_dir, exist_ok=True)
    plt.savefig(f'{output_dir}/feature_importance_{model_type}.png', dpi=150)
    print(f"âœ… íŠ¹ì„± ì¤‘ìš”ë„ ê·¸ë˜í”„ ì €ì¥: {output_dir}/feature_importance_{model_type}.png")
    plt.close()


def save_model(model, features, metrics, model_type, mode='pre'):
    """ëª¨ë¸ ì €ì¥"""
    output_dir = os.path.join('ml_models', mode)
    os.makedirs(output_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    prefix = f'{mode}_{model_type}_{timestamp}'
    
    # ëª¨ë¸ ì €ì¥
    model_path = f'{output_dir}/iracing_rank_predictor_{prefix}.pkl'
    joblib.dump(model, model_path)
    print(f"âœ… ëª¨ë¸ ì €ì¥: {model_path}")
    
    # íŠ¹ì„± ëª©ë¡ ì €ì¥
    features_path = f'{output_dir}/model_features_{prefix}.json'
    with open(features_path, 'w') as f:
        json.dump(features, f, indent=2)
    print(f"âœ… íŠ¹ì„± ëª©ë¡ ì €ì¥: {features_path}")
    
    # ë©”íƒ€ë°ì´í„° ì €ì¥
    metadata = {
        'model_type': model_type,
        'mode': mode,
        'timestamp': timestamp,
        'features': features,
        'metrics': {
            'mae': float(metrics['mae']),
            'rmse': float(metrics['rmse']),
            'r2': float(metrics['r2'])
        }
    }
    metadata_path = f'{output_dir}/model_metadata_{prefix}.json'
    with open(metadata_path, 'w') as f:
        json.dump(metadata, f, indent=2)
    print(f"âœ… ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_path}")
    
    return model_path, features_path, metadata_path


def train_specialized_models(df_clean, features, target='actual_finish_position'):
    """ìœ ì €ë³„, íŠ¸ë™ë³„, ì°¨ëŸ‰ë³„ íŠ¹í™” ëª¨ë¸ í•™ìŠµ"""
    print("\n" + "="*60)
    print("ğŸ¯ íŠ¹í™” ëª¨ë¸ í•™ìŠµ ì‹œì‘\n")
    
    specialized_results = {}
    
    # 1. ìœ ì €ë³„ íŠ¹í™” ëª¨ë¸ (ë°ì´í„°ê°€ ë§ì€ ìœ ì €ë§Œ)
    print("ğŸ‘¤ ìœ ì €ë³„ íŠ¹í™” ëª¨ë¸ í•™ìŠµ ì¤‘...")
    user_counts = df_clean['cust_id'].value_counts()
    top_users = user_counts[user_counts >= 50].index  # ìµœì†Œ 50ê°œ ë ˆì½”ë“œ ì´ìƒ
    
    if len(top_users) > 0:
        print(f"   {len(top_users)}ëª…ì˜ ìœ ì €ì— ëŒ€í•´ íŠ¹í™” ëª¨ë¸ í•™ìŠµ (ìµœì†Œ 50ê°œ ë ˆì½”ë“œ)")
        user_models = {}
        for user_id in top_users[:10]:  # ìƒìœ„ 10ëª…ë§Œ (ì‹œê°„ ì ˆì•½)
            user_data = df_clean[df_clean['cust_id'] == user_id]
            if len(user_data) < 30:  # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¥¼ ìœ„í•´ ìµœì†Œ 30ê°œ í•„ìš”
                continue
            
            X_user = user_data[features].values
            y_user = user_data[target].values
            
            if len(X_user) < 30:
                continue
            
            X_train, X_test, y_train, y_test = train_test_split(
                X_user, y_user, test_size=0.2, random_state=42
            )
            
            # ê°„ë‹¨í•œ ëª¨ë¸ í•™ìŠµ (ë°ì´í„°ê°€ ì ìœ¼ë¯€ë¡œ)
            model = GradientBoostingRegressor(
                n_estimators=100,
                learning_rate=0.1,
                max_depth=5,
                random_state=42
            )
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            
            mae = mean_absolute_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)
            
            user_models[user_id] = {
                'model': model,
                'mae': mae,
                'r2': r2,
                'samples': len(user_data)
            }
            
            if len(user_models) % 5 == 0:
                print(f"   ì§„í–‰: {len(user_models)}/{min(10, len(top_users))}ëª… ì™„ë£Œ")
        
        if user_models:
            avg_r2 = np.mean([m['r2'] for m in user_models.values()])
            avg_mae = np.mean([m['mae'] for m in user_models.values()])
            print(f"   âœ… ìœ ì €ë³„ ëª¨ë¸: í‰ê·  RÂ²={avg_r2:.4f}, í‰ê·  MAE={avg_mae:.2f} ({len(user_models)}ê°œ ëª¨ë¸)")
            specialized_results['user_models'] = user_models
    
    # 2. íŠ¸ë™ë³„ íŠ¹í™” ëª¨ë¸
    print("\nğŸ íŠ¸ë™ë³„ íŠ¹í™” ëª¨ë¸ í•™ìŠµ ì¤‘...")
    if 'track_id' in df_clean.columns:
        track_counts = df_clean['track_id'].value_counts()
        top_tracks = track_counts[track_counts >= 100].index  # ìµœì†Œ 100ê°œ ë ˆì½”ë“œ ì´ìƒ
        
        if len(top_tracks) > 0:
            print(f"   {len(top_tracks)}ê°œ íŠ¸ë™ì— ëŒ€í•´ íŠ¹í™” ëª¨ë¸ í•™ìŠµ (ìµœì†Œ 100ê°œ ë ˆì½”ë“œ)")
            track_models = {}
            for track_id in top_tracks[:10]:  # ìƒìœ„ 10ê°œë§Œ
                track_data = df_clean[df_clean['track_id'] == track_id]
                if len(track_data) < 50:
                    continue
                
                X_track = track_data[features].values
                y_track = track_data[target].values
                
                X_train, X_test, y_train, y_test = train_test_split(
                    X_track, y_track, test_size=0.2, random_state=42
                )
                
                model = GradientBoostingRegressor(
                    n_estimators=200,
                    learning_rate=0.1,
                    max_depth=8,
                    random_state=42
                )
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                
                mae = mean_absolute_error(y_test, y_pred)
                r2 = r2_score(y_test, y_pred)
                
                track_models[track_id] = {
                    'model': model,
                    'mae': mae,
                    'r2': r2,
                    'samples': len(track_data)
                }
            
            if track_models:
                avg_r2 = np.mean([m['r2'] for m in track_models.values()])
                avg_mae = np.mean([m['mae'] for m in track_models.values()])
                print(f"   âœ… íŠ¸ë™ë³„ ëª¨ë¸: í‰ê·  RÂ²={avg_r2:.4f}, í‰ê·  MAE={avg_mae:.2f} ({len(track_models)}ê°œ ëª¨ë¸)")
                specialized_results['track_models'] = track_models
    
    # 3. ì°¨ëŸ‰ë³„ íŠ¹í™” ëª¨ë¸
    print("\nğŸš— ì°¨ëŸ‰ë³„ íŠ¹í™” ëª¨ë¸ í•™ìŠµ ì¤‘...")
    if 'car_id' in df_clean.columns:
        car_counts = df_clean['car_id'].value_counts()
        top_cars = car_counts[car_counts >= 100].index  # ìµœì†Œ 100ê°œ ë ˆì½”ë“œ ì´ìƒ
        
        if len(top_cars) > 0:
            print(f"   {len(top_cars)}ê°œ ì°¨ëŸ‰ì— ëŒ€í•´ íŠ¹í™” ëª¨ë¸ í•™ìŠµ (ìµœì†Œ 100ê°œ ë ˆì½”ë“œ)")
            car_models = {}
            for car_id in top_cars[:10]:  # ìƒìœ„ 10ê°œë§Œ
                car_data = df_clean[df_clean['car_id'] == car_id]
                if len(car_data) < 50:
                    continue
                
                X_car = car_data[features].values
                y_car = car_data[target].values
                
                X_train, X_test, y_train, y_test = train_test_split(
                    X_car, y_car, test_size=0.2, random_state=42
                )
                
                model = GradientBoostingRegressor(
                    n_estimators=200,
                    learning_rate=0.1,
                    max_depth=8,
                    random_state=42
                )
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                
                mae = mean_absolute_error(y_test, y_pred)
                r2 = r2_score(y_test, y_pred)
                
                car_models[car_id] = {
                    'model': model,
                    'mae': mae,
                    'r2': r2,
                    'samples': len(car_data)
                }
            
            if car_models:
                avg_r2 = np.mean([m['r2'] for m in car_models.values()])
                avg_mae = np.mean([m['mae'] for m in car_models.values()])
                print(f"   âœ… ì°¨ëŸ‰ë³„ ëª¨ë¸: í‰ê·  RÂ²={avg_r2:.4f}, í‰ê·  MAE={avg_mae:.2f} ({len(car_models)}ê°œ ëª¨ë¸)")
                specialized_results['car_models'] = car_models
    
    return specialized_results


def main(mode='pre', tune_hyperparams=False):
    """ë©”ì¸ í•¨ìˆ˜
    
    Args:
        mode: 'pre' (ë ˆì´ìŠ¤ ì „) ë˜ëŠ” 'post' (ê·¸ë¦¬ë“œ ë°˜ì˜)
        tune_hyperparams: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì—¬ë¶€ (ê¸°ë³¸ê°’: False, ì‹œê°„ ì†Œìš”)
    """
    print(f"ğŸš€ iRacing ìˆœìœ„ ì˜ˆì¸¡ ML ëª¨ë¸ í•™ìŠµ ì‹œì‘ (mode={mode})\n")
    if tune_hyperparams:
        print("âš™ï¸  í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ëª¨ë“œ í™œì„±í™” (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\n")
    
    # 1. ë°ì´í„° ë¡œë“œ
    df = load_data()
    
    # 2. ë°ì´í„° ì „ì²˜ë¦¬
    df_clean = preprocess_data(df)
    
    # 3. ì¹´í…Œê³ ë¦¬ ë³€ìˆ˜ ì¸ì½”ë”©
    categorical_cols = ['series_id', 'track_id', 'car_id']
    df_encoded, encoder, encoded_feature_names = encode_categorical_features(
        df_clean, categorical_cols, use_onehot=True
    )
    
    # 4. íŠ¹ì„± ì„ íƒ (ë ˆì´ìŠ¤ ì‹œì‘ ì „ì— ì•Œ ìˆ˜ ìˆëŠ” í•„ë“œë§Œ!)
    # âš ï¸ ì£¼ì˜: starting_position, laps_completeëŠ” ë ˆì´ìŠ¤ ì¢…ë£Œ í›„ ì •ë³´ì´ë¯€ë¡œ ì œì™¸
    base_features = [
        # í•µì‹¬ íŠ¹ì„± (ë ˆì´ìŠ¤ ì‹œì‘ ì „ ì•Œ ìˆ˜ ìˆìŒ)
        'i_rating',
        'safety_rating',
        
        # ìƒëŒ€ ì „ë ¥ í†µê³„ (í•µì‹¬!) - ë ˆì´ìŠ¤ ì‹œì‘ ì „ ì•Œ ìˆ˜ ìˆìŒ
        'avg_opponent_ir',
        'max_opponent_ir',
        'min_opponent_ir',
        'ir_diff_from_avg',
        'sof',
        
        # íŒŒìƒ ë³€ìˆ˜ (ìƒëŒ€ ì „ë ¥ ê¸°ë°˜)
        'ir_advantage',
        'ir_range',
        'ir_rank_pct',
        'ir_vs_max',
        'ir_vs_min',
        'ir_std_estimate',
        'ir_relative_to_sof',
        
        # ì£¼í–‰ íŠ¹ì„± (ê³¼ê±° ë°ì´í„°, ë ˆì´ìŠ¤ ì‹œì‘ ì „ ì•Œ ìˆ˜ ìˆìŒ)
        'best_lap_time',
        'average_lap_time',
        'lap_time_diff',
        'lap_time_consistency',
        
        # ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ (ë ˆì´ìŠ¤ ì‹œì‘ ì „ ì•Œ ìˆ˜ ìˆìŒ)
        'total_participants',
        
        # ìœ ì €ë³„ ìƒëŒ€ ì „ë ¥(ir_diff_from_avg) êµ¬ê°„ë³„ ì„±ëŠ¥ íŠ¹ì„± (í•µì‹¬!)
        # ë‚´ iRating vs ìƒëŒ€ í‰ê·  iRating ì°¨ì´ì— ë”°ë¥¸ ì„±ëŠ¥ íŒ¨í„´
        'user_avg_finish_pct_much_lower',  # ë‚´ê°€ ìƒëŒ€ë³´ë‹¤ 200+ ë‚®ì„ ë•Œ â†’ ê°•í•œ ìƒëŒ€
        'user_avg_finish_pct_lower',       # ë‚´ê°€ ìƒëŒ€ë³´ë‹¤ 50-200 ë‚®ì„ ë•Œ â†’ ì•½ê°„ ê°•í•œ ìƒëŒ€
        'user_avg_finish_pct_similar',    # ë¹„ìŠ·í•  ë•Œ
        'user_avg_finish_pct_higher',     # ë‚´ê°€ ìƒëŒ€ë³´ë‹¤ 50-200 ë†’ì„ ë•Œ â†’ ì•½ê°„ ì•½í•œ ìƒëŒ€
        'user_avg_finish_pct_much_higher', # ë‚´ê°€ ìƒëŒ€ë³´ë‹¤ 200+ ë†’ì„ ë•Œ â†’ ì•½í•œ ìƒëŒ€
        'user_ir_diff_performance_diff',   # ê°•í•œ ìƒëŒ€ì—ì„œì˜ ì„±ëŠ¥ - ì•½í•œ ìƒëŒ€ì—ì„œì˜ ì„±ëŠ¥
        'user_expected_finish_pct_by_ir_diff',  # í˜„ì¬ ìƒëŒ€ ì „ë ¥ êµ¬ê°„ì—ì„œì˜ ì˜ˆìƒ ì„±ëŠ¥
        
        # ì‚¬ê³  ì˜í–¥ë„ íŠ¹ì„± (ì‚¬ê³  ë°œìƒ ì‹œ ìˆœìœ„ ë³€ë™ ë°˜ì˜)
        'incident_impact_on_position',      # ì‚¬ê³  ë°œìƒ ì‹œ í‰ê·  ìˆœìœ„ í•˜ë½ (ì™„ì£¼ìœ¨ ë‹¨ìœ„)
        'incident_impact_rank_drop',        # ì‚¬ê³  ë°œìƒ ì‹œ í‰ê·  ìˆœìœ„ í•˜ë½ (ìˆœìœ„ ë‹¨ìœ„)
        'high_incident_risk',              # ì‚¬ê³  ë°œìƒ í™•ë¥ ì´ ë†’ì€ì§€ ì—¬ë¶€ (0/1)
    ]
    
    if mode == 'post':
        base_features += POST_ONLY_FEATURES
    
    # ì¸ì½”ë”©ëœ ì¹´í…Œê³ ë¦¬ íŠ¹ì„± ì¶”ê°€
    if encoded_feature_names:
        features = base_features + encoded_feature_names
        print(f"\nğŸ“Š ì´ íŠ¹ì„± ìˆ˜: {len(base_features)} (ê¸°ë³¸) + {len(encoded_feature_names)} (ì¸ì½”ë”©) = {len(features)}ê°œ")
    else:
        features = base_features
        print(f"\nğŸ“Š ì´ íŠ¹ì„± ìˆ˜: {len(features)}ê°œ")
    
    # ì œì™¸ëœ í•„ë“œ (ë ˆì´ìŠ¤ ì‹œì‘ ì „ì— ì•Œ ìˆ˜ ì—†ìŒ):
    # - starting_position: ë ˆì´ìŠ¤ ì‹œì‘ ì „ì—ëŠ” ì•Œ ìˆ˜ ì—†ìŒ (í€„ë¦¬íŒŒì‰ ê²°ê³¼ í•„ìš”)
    # - laps_complete: ë ˆì´ìŠ¤ ì¢…ë£Œ í›„ì—ë§Œ ì•Œ ìˆ˜ ìˆìŒ
    
    # íŠ¹ì„±ì´ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸
    missing_features = [f for f in features if f not in df_encoded.columns]
    if missing_features:
        print(f"âš ï¸  ëˆ„ë½ëœ íŠ¹ì„±: {missing_features}")
        features = [f for f in features if f in df_encoded.columns]
    
    # 5. ë°ì´í„° ì¤€ë¹„
    X = df_encoded[features].values
    y = df_encoded['actual_finish_position'].values
    
    print(f"\nğŸ“Š ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ:")
    print(f"   íŠ¹ì„± ìˆ˜: {len(features)}")
    print(f"   ìƒ˜í”Œ ìˆ˜: {len(X)}")
    
    # 5. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    print(f"   í•™ìŠµ ì„¸íŠ¸: {len(X_train)}ê°œ")
    print(f"   í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: {len(X_test)}ê°œ")
    
    # 6. íŠ¹í™” ëª¨ë¸ í•™ìŠµ (ìœ ì €ë³„, íŠ¸ë™ë³„, ì°¨ëŸ‰ë³„)
    specialized_results = train_specialized_models(df_encoded, features)
    
    # 7. ëª¨ë¸ í•™ìŠµ (ì—¬ëŸ¬ ëª¨ë¸ ì‹œë„)
    all_models = {}
    all_metrics = {}
    all_model_paths = {}  # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì €ì¥
    
    # Random Forest
    print("\n" + "="*60)
    model_rf, metrics_rf = train_model(X_train, y_train, X_test, y_test, 'random_forest', tune_hyperparams=tune_hyperparams)
    plot_feature_importance(model_rf, features, 'random_forest')
    model_path_rf, _, _ = save_model(model_rf, features, metrics_rf, 'random_forest', mode=mode)
    all_models['random_forest'] = model_rf
    all_metrics['random_forest'] = metrics_rf
    all_model_paths['random_forest'] = model_path_rf
    
    # Gradient Boosting
    print("\n" + "="*60)
    model_gb, metrics_gb = train_model(X_train, y_train, X_test, y_test, 'gradient_boosting', tune_hyperparams=tune_hyperparams)
    plot_feature_importance(model_gb, features, 'gradient_boosting')
    model_path_gb, _, _ = save_model(model_gb, features, metrics_gb, 'gradient_boosting', mode=mode)
    all_models['gradient_boosting'] = model_gb
    all_metrics['gradient_boosting'] = metrics_gb
    all_model_paths['gradient_boosting'] = model_path_gb
    
    # XGBoost (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
    if XGBOOST_AVAILABLE:
        print("\n" + "="*60)
        model_xgb, metrics_xgb = train_model(X_train, y_train, X_test, y_test, 'xgboost', tune_hyperparams=tune_hyperparams)
        plot_feature_importance(model_xgb, features, 'xgboost')
        model_path_xgb, _, _ = save_model(model_xgb, features, metrics_xgb, 'xgboost', mode=mode)
        all_models['xgboost'] = model_xgb
        all_metrics['xgboost'] = metrics_xgb
        all_model_paths['xgboost'] = model_path_xgb
    
    # LightGBM (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
    if LIGHTGBM_AVAILABLE:
        print("\n" + "="*60)
        model_lgb, metrics_lgb = train_model(X_train, y_train, X_test, y_test, 'lightgbm', tune_hyperparams=tune_hyperparams)
        plot_feature_importance(model_lgb, features, 'lightgbm')
        model_path_lgb, _, _ = save_model(model_lgb, features, metrics_lgb, 'lightgbm', mode=mode)
        all_models['lightgbm'] = model_lgb
        all_metrics['lightgbm'] = metrics_lgb
        all_model_paths['lightgbm'] = model_path_lgb
    
    # 8. ì•™ìƒë¸” ëª¨ë¸ (ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë“¤ ì¡°í•©)
    print("\n" + "="*60)
    print("ğŸ¯ ì•™ìƒë¸” ëª¨ë¸ ìƒì„± ì¤‘...")
    
    # RÂ² ì ìˆ˜ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ ëª¨ë¸ ì„ íƒ
    sorted_models = sorted(all_metrics.items(), key=lambda x: x[1]['r2'], reverse=True)
    top_models = sorted_models[:min(3, len(sorted_models))]  # ìƒìœ„ 3ê°œ ëª¨ë¸
    
    if len(top_models) >= 2:
        # ê°€ì¤‘ í‰ê·  ì•™ìƒë¸” (RÂ² ì ìˆ˜ ê¸°ë°˜ ê°€ì¤‘ì¹˜)
        total_r2 = sum(m[1]['r2'] for m in top_models)
        weights = [m[1]['r2'] / total_r2 for m in top_models]
        
        ensemble_pred = np.zeros(len(y_test))
        for i, (name, metrics) in enumerate(top_models):
            weight = weights[i]
            pred = all_models[name].predict(X_test)
            ensemble_pred += weight * pred
            print(f"   {name}: ê°€ì¤‘ì¹˜ {weight:.3f} (RÂ²={metrics['r2']:.4f})")
        
        # ì•™ìƒë¸” í‰ê°€
        ensemble_mae = mean_absolute_error(y_test, ensemble_pred)
        ensemble_rmse = np.sqrt(mean_squared_error(y_test, ensemble_pred))
        ensemble_r2 = r2_score(y_test, ensemble_pred)
        
        print(f"âœ… ì•™ìƒë¸” ëª¨ë¸ ì„±ëŠ¥:")
        print(f"   MAE: {ensemble_mae:.2f}")
        print(f"   RMSE: {ensemble_rmse:.2f}")
        print(f"   RÂ²: {ensemble_r2:.4f}")
        
        # ì•™ìƒë¸” ëª¨ë¸ ì €ì¥
        ensemble_timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        ensemble_config = {
            'model_type': 'ensemble',
            'timestamp': ensemble_timestamp,
            'mode': mode,
            'features': features,
            'models': [
                {
                    'name': name,
                    'weight': float(weight),
                    'r2': float(metrics['r2']),
                    'model_path': os.path.relpath(all_model_paths.get(name), os.path.join('ml_models', mode)) if all_model_paths.get(name) else f'iracing_rank_predictor_{mode}_{name}_{ensemble_timestamp}.pkl'
                }
                for (name, metrics), weight in zip(top_models, weights)
            ],
            'metrics': {
                'mae': float(ensemble_mae),
                'rmse': float(ensemble_rmse),
                'r2': float(ensemble_r2)
            }
        }
        
        output_dir = os.path.join('ml_models', mode)
        os.makedirs(output_dir, exist_ok=True)
        ensemble_config_path = f'{output_dir}/ensemble_config_{mode}_{ensemble_timestamp}.json'
        with open(ensemble_config_path, 'w') as f:
            json.dump(ensemble_config, f, indent=2)
        print(f"âœ… ì•™ìƒë¸” ì„¤ì • ì €ì¥: {ensemble_config_path}")
        print(f"   ì‚¬ìš© ëª¨ë¸: {', '.join([m['name'] for m in ensemble_config['models']])}")
    
    # 9. íŠ¹í™” ëª¨ë¸ ê²°ê³¼ ìš”ì•½
    if specialized_results:
        print("\n" + "="*60)
        print("ğŸ“Š íŠ¹í™” ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½:")
        if 'user_models' in specialized_results:
            user_r2s = [m['r2'] for m in specialized_results['user_models'].values()]
            print(f"   ìœ ì €ë³„ ëª¨ë¸: í‰ê·  RÂ²={np.mean(user_r2s):.4f} (ìµœê³ : {max(user_r2s):.4f}, ìµœì €: {min(user_r2s):.4f})")
        if 'track_models' in specialized_results:
            track_r2s = [m['r2'] for m in specialized_results['track_models'].values()]
            print(f"   íŠ¸ë™ë³„ ëª¨ë¸: í‰ê·  RÂ²={np.mean(track_r2s):.4f} (ìµœê³ : {max(track_r2s):.4f}, ìµœì €: {min(track_r2s):.4f})")
        if 'car_models' in specialized_results:
            car_r2s = [m['r2'] for m in specialized_results['car_models'].values()]
            print(f"   ì°¨ëŸ‰ë³„ ëª¨ë¸: í‰ê·  RÂ²={np.mean(car_r2s):.4f} (ìµœê³ : {max(car_r2s):.4f}, ìµœì €: {min(car_r2s):.4f})")
    
    # 10. ê²°ê³¼ ë¹„êµ
    print("\n" + "="*60)
    print("ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ:")
    for name, metrics in sorted(all_metrics.items(), key=lambda x: x[1]['r2'], reverse=True):
        print(f"   {name:20s}: MAE={metrics['mae']:.2f}, RMSE={metrics['rmse']:.2f}, RÂ²={metrics['r2']:.4f}")
    
    if len(top_models) >= 2:
        print(f"   {'Ensemble':20s}: MAE={ensemble_mae:.2f}, RMSE={ensemble_rmse:.2f}, RÂ²={ensemble_r2:.4f}")
    
    print("\nâœ… í•™ìŠµ ì™„ë£Œ!")
    print("\nğŸ’¡ ì„±ëŠ¥ ê°œì„  íŒ:")
    print("   1. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹: tune_hyperparams=Trueë¡œ ì„¤ì • (ì‹œê°„ ì†Œìš”)")
    print("   2. ë” ë§ì€ ë°ì´í„° ìˆ˜ì§‘: í˜„ì¬ 31,025ê°œ â†’ ëª©í‘œ 50,000ê°œ ì´ìƒ")
    print("   3. âœ… ì¹´í…Œê³ ë¦¬ ë³€ìˆ˜ ì¸ì½”ë”©: ì™„ë£Œ (series_id, track_id, car_id)")
    print("   4. âœ… íŠ¹í™” ëª¨ë¸: ì™„ë£Œ (ìœ ì €ë³„, íŠ¸ë™ë³„, ì°¨ëŸ‰ë³„)")
    print("   5. íŠ¸ë™/ì°¨ëŸ‰ ì¡°í•©ë³„ ëª¨ë¸: íŠ¹ì • íŠ¸ë™+ì°¨ëŸ‰ ì¡°í•©ì— ëŒ€í•œ ëª¨ë¸ í•™ìŠµ")
    print("   6. ì‹œê°„ëŒ€ë³„ ëª¨ë¸: ì‹œì¦Œ, íŒ¨ì¹˜ë³„ë¡œ ëª¨ë¸ ë¶„ë¦¬")


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='iRacing ìˆœìœ„ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ')
    parser.add_argument('--mode', choices=['pre', 'post'], default='pre', help='ëª¨ë¸ ëª¨ë“œ ì„ íƒ (pre: ë ˆì´ìŠ¤ ì „, post: ê·¸ë¦¬ë“œ ë°˜ì˜)')
    parser.add_argument('--tune', '-t', action='store_true', help='í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ í™œì„±í™”')
    args = parser.parse_args()
    main(mode=args.mode, tune_hyperparams=args.tune)

