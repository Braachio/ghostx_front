"""
ì•™ìƒë¸” ëª¨ë¸ ë¡œë“œ ë° ì˜ˆì¸¡ ìœ í‹¸ë¦¬í‹°

ì‚¬ìš©ë²•:
    from scripts.load_ensemble_model import load_ensemble_model, predict_rank
    
    # ì•™ìƒë¸” ëª¨ë¸ ë¡œë“œ
    ensemble = load_ensemble_model('ml_models/ensemble_config_20251119_160720.json')
    
    # ì˜ˆì¸¡
    features = [...]  # íŠ¹ì„± ë²¡í„°
    predicted_rank = predict_rank(ensemble, features)
"""

import json
import joblib
import numpy as np
from pathlib import Path
from typing import Dict, List, Any, Optional


def load_ensemble_model(config_path: str) -> Dict[str, Any]:
    """
    ì•™ìƒë¸” ëª¨ë¸ ì„¤ì • íŒŒì¼ ë¡œë“œ
    
    Args:
        config_path: ì•™ìƒë¸” ì„¤ì • JSON íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ì•™ìƒë¸” ì„¤ì • ë”•ì…”ë„ˆë¦¬ (ëª¨ë¸ ê°ì²´ í¬í•¨)
    """
    config_path = Path(config_path)
    if not config_path.exists():
        raise FileNotFoundError(f"ì•™ìƒë¸” ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
    
    with open(config_path, 'r') as f:
        config = json.load(f)
    
    # ê° ëª¨ë¸ ë¡œë“œ
    config_dir = config_path.parent
    loaded_models = []
    
    for model_info in config['models']:
        model_file = config_dir / model_info['model_path']
        if not model_file.exists():
            # íŒŒì¼ëª…ë§Œ ìˆëŠ” ê²½ìš° íŒŒì¼ëª…ìœ¼ë¡œ ê²€ìƒ‰
            model_file = list(config_dir.glob(f"*{model_info['name']}*.pkl"))
            if model_file:
                model_file = model_file[0]
            else:
                raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_info['model_path']}")
        
        model = joblib.load(model_file)
        loaded_models.append({
            'name': model_info['name'],
            'model': model,
            'weight': model_info['weight'],
            'r2': model_info['r2']
        })
        print(f"âœ… {model_info['name']} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ê°€ì¤‘ì¹˜: {model_info['weight']:.3f})")
    
    config['loaded_models'] = loaded_models
    print(f"\nâœ… ì•™ìƒë¸” ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {len(loaded_models)}ê°œ ëª¨ë¸")
    print(f"   ì˜ˆìƒ ì„±ëŠ¥: RÂ²={config['metrics']['r2']:.4f}, MAE={config['metrics']['mae']:.2f}")
    
    return config


def predict_rank(ensemble: Dict[str, Any], features: np.ndarray) -> float:
    """
    ì•™ìƒë¸” ëª¨ë¸ë¡œ ìˆœìœ„ ì˜ˆì¸¡
    
    Args:
        ensemble: load_ensemble_model()ë¡œ ë¡œë“œí•œ ì•™ìƒë¸” ì„¤ì •
        features: íŠ¹ì„± ë²¡í„° (1D ë°°ì—´ ë˜ëŠ” 2D ë°°ì—´)
        
    Returns:
        ì˜ˆì¸¡ëœ ìˆœìœ„ (float)
    """
    if 'loaded_models' not in ensemble:
        raise ValueError("ì•™ìƒë¸” ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_ensemble_model()ì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
    
    # featuresë¥¼ 2D ë°°ì—´ë¡œ ë³€í™˜
    if features.ndim == 1:
        features = features.reshape(1, -1)
    
    # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ê°€ì¤‘ í‰ê· 
    ensemble_pred = 0.0
    
    for model_info in ensemble['loaded_models']:
        model = model_info['model']
        weight = model_info['weight']
        pred = model.predict(features)[0]  # ì²« ë²ˆì§¸ ìƒ˜í”Œì˜ ì˜ˆì¸¡
        ensemble_pred += weight * pred
    
    return float(ensemble_pred)


def predict_ranks_batch(ensemble: Dict[str, Any], features_array: np.ndarray) -> np.ndarray:
    """
    ì•™ìƒë¸” ëª¨ë¸ë¡œ ì—¬ëŸ¬ ìƒ˜í”Œì˜ ìˆœìœ„ ì˜ˆì¸¡ (ë°°ì¹˜)
    
    Args:
        ensemble: load_ensemble_model()ë¡œ ë¡œë“œí•œ ì•™ìƒë¸” ì„¤ì •
        features_array: íŠ¹ì„± ë°°ì—´ (2D: [n_samples, n_features])
        
    Returns:
        ì˜ˆì¸¡ëœ ìˆœìœ„ ë°°ì—´ (1D: [n_samples])
    """
    if 'loaded_models' not in ensemble:
        raise ValueError("ì•™ìƒë¸” ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. load_ensemble_model()ì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
    
    if features_array.ndim != 2:
        raise ValueError("features_arrayëŠ” 2D ë°°ì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤: [n_samples, n_features]")
    
    # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ê°€ì¤‘ í‰ê· 
    ensemble_pred = np.zeros(features_array.shape[0])
    
    for model_info in ensemble['loaded_models']:
        model = model_info['model']
        weight = model_info['weight']
        pred = model.predict(features_array)
        ensemble_pred += weight * pred
    
    return ensemble_pred


def find_latest_ensemble_config(models_dir: str = 'ml_models') -> Optional[str]:
    """
    ê°€ì¥ ìµœê·¼ ì•™ìƒë¸” ì„¤ì • íŒŒì¼ ì°¾ê¸°
    
    Args:
        models_dir: ëª¨ë¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        
    Returns:
        ê°€ì¥ ìµœê·¼ ì•™ìƒë¸” ì„¤ì • íŒŒì¼ ê²½ë¡œ (ì—†ìœ¼ë©´ None)
    """
    models_path = Path(models_dir)
    if not models_path.exists():
        return None
    
    ensemble_configs = list(models_path.glob('ensemble_config_*.json'))
    if not ensemble_configs:
        return None
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ì •ë ¬ (íŒŒì¼ëª…ì— í¬í•¨ë¨)
    latest = sorted(ensemble_configs, key=lambda p: p.stat().st_mtime, reverse=True)[0]
    return str(latest)


if __name__ == '__main__':
    # í…ŒìŠ¤íŠ¸
    print("ğŸ” ìµœì‹  ì•™ìƒë¸” ëª¨ë¸ ì°¾ê¸°...")
    latest_config = find_latest_ensemble_config()
    
    if latest_config:
        print(f"âœ… ìµœì‹  ì•™ìƒë¸” ì„¤ì •: {latest_config}")
        ensemble = load_ensemble_model(latest_config)
        print(f"\nğŸ“Š ì•™ìƒë¸” ì •ë³´:")
        print(f"   íŠ¹ì„± ìˆ˜: {len(ensemble['features'])}")
        print(f"   ëª¨ë¸ ìˆ˜: {len(ensemble['loaded_models'])}")
        print(f"   ì„±ëŠ¥: RÂ²={ensemble['metrics']['r2']:.4f}, MAE={ensemble['metrics']['mae']:.2f}")
    else:
        print("âŒ ì•™ìƒë¸” ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


